{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:11:50.408638800Z",
     "start_time": "2023-10-01T19:11:50.408638800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m pickle_X_in \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m X \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(pickle_X_in)\n\u001B[0;32m      4\u001B[0m pickle_y_in \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      5\u001B[0m y \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(pickle_y_in)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "pickle_X_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_X_in)\n",
    "\n",
    "pickle_y_in = open(\"y.pickle\", \"rb\")\n",
    "y = pickle.load(pickle_y_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:00:15.873509200Z",
     "start_time": "2023-10-01T20:00:10.835516900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Find the optimal activation function and regularization parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.9319 - accuracy: 0.5114 - val_loss: 0.9465 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.8911 - accuracy: 0.6193 - val_loss: 0.8915 - val_accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.8561 - accuracy: 0.7443 - val_loss: 0.8416 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.8331 - accuracy: 0.7216 - val_loss: 0.8034 - val_accuracy: 0.7000\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 10s 1s/step - loss: 0.8088 - accuracy: 0.7670 - val_loss: 0.7918 - val_accuracy: 0.6500\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 3.2437 - accuracy: 0.4886 - val_loss: 3.2179 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 9s 2s/step - loss: 3.1636 - accuracy: 0.5284 - val_loss: 3.1404 - val_accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 9s 2s/step - loss: 3.0895 - accuracy: 0.6477 - val_loss: 3.0648 - val_accuracy: 0.6000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 3.0129 - accuracy: 0.6818 - val_loss: 3.0107 - val_accuracy: 0.6000\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 2.9396 - accuracy: 0.7557 - val_loss: 2.9018 - val_accuracy: 0.6500\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 26.2590 - accuracy: 0.5284 - val_loss: 25.9058 - val_accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 9s 2s/step - loss: 25.6414 - accuracy: 0.6136 - val_loss: 25.2827 - val_accuracy: 0.6000\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 9s 1s/step - loss: 25.0405 - accuracy: 0.6250 - val_loss: 24.7085 - val_accuracy: 0.6000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 9s 1s/step - loss: 24.4522 - accuracy: 0.7045 - val_loss: 24.1113 - val_accuracy: 0.5500\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 9s 1s/step - loss: 23.8753 - accuracy: 0.7614 - val_loss: 23.5479 - val_accuracy: 0.6000\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.9570 - accuracy: 0.5966 - val_loss: 0.8450 - val_accuracy: 0.8000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.8480 - accuracy: 0.6875 - val_loss: 0.8264 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.8066 - accuracy: 0.7102 - val_loss: 0.7615 - val_accuracy: 0.8000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.7908 - accuracy: 0.7443 - val_loss: 0.7881 - val_accuracy: 0.7000\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 0.7589 - accuracy: 0.7614 - val_loss: 0.7632 - val_accuracy: 0.7500\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 3.2722 - accuracy: 0.5739 - val_loss: 3.2302 - val_accuracy: 0.5500\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 11s 2s/step - loss: 3.1402 - accuracy: 0.6591 - val_loss: 3.0471 - val_accuracy: 0.8000\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 3.0559 - accuracy: 0.7216 - val_loss: 3.0476 - val_accuracy: 0.6000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 3.0056 - accuracy: 0.7784 - val_loss: 2.9507 - val_accuracy: 0.7500\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 2.9475 - accuracy: 0.7216 - val_loss: 2.8984 - val_accuracy: 0.8000\n",
      "Epoch 1/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 26.1484 - accuracy: 0.6420 - val_loss: 25.7041 - val_accuracy: 0.7000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 25.4989 - accuracy: 0.7102 - val_loss: 25.1771 - val_accuracy: 0.5500\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 24.8848 - accuracy: 0.7557 - val_loss: 24.4923 - val_accuracy: 0.7500\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 10s 2s/step - loss: 24.2987 - accuracy: 0.7443 - val_loss: 23.9668 - val_accuracy: 0.6500\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 11s 2s/step - loss: 23.7330 - accuracy: 0.7614 - val_loss: 23.3939 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "activations = ['relu', 'tanh']\n",
    "regularizer_values = [0.001, 0.01, 0.1]\n",
    "\n",
    "for activation in activations:\n",
    "    for regularizer in regularizer_values:\n",
    "        name = \"{}-activation-{}-regularizer-{}\".format(activation,regularizer, int(time.time()))\n",
    "        model = Sequential([\n",
    "                Conv2D(128, (2, 2), activation=activation, kernel_regularizer=regularizers.l2(regularizer)),\n",
    "                AveragePooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(128, (2, 2), activation=activation, kernel_regularizer=regularizers.l2(regularizer)),\n",
    "                AveragePooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Conv2D(128, (2, 2), activation=activation, kernel_regularizer=regularizers.l2(regularizer)),\n",
    "                AveragePooling2D(pool_size=(2, 2)),\n",
    "\n",
    "                Flatten(),\n",
    "                Dense(128, activation=activation),\n",
    "                Dense(1, activation=\"sigmoid\")\n",
    "        ])\n",
    "\n",
    "        learning_rate_schedule = ExponentialDecay( 0.0001, 1500, 0.8 )\n",
    "\n",
    "        opt = Adam(learning_rate=learning_rate_schedule)\n",
    "\n",
    "        model.compile(\n",
    "            loss='binary_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics = ['accuracy']\n",
    "        )\n",
    "\n",
    "        tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"activation_regularizer_logs/{}\".format(name))\n",
    "        history = model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_val, y_val), shuffle=True,callbacks=[tensorboard])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T19:17:59.219475Z",
     "start_time": "2023-10-01T19:12:48.998605300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nAfter examining the graphs provided by Tensorboard, we find that the model performs best with\\nthe tanh activation and 0.01 as regularization parameter\\n'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "After examining the graphs provided by Tensorboard, we find that the model performs best with\n",
    "the tanh activation and 0.01 as regularization parameter\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-01T20:01:53.884912Z",
     "start_time": "2023-10-01T20:01:53.721583100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
